ocr_model:
  segment_yolov8:
    weight: "./ckpt_saved_model/segment_yolov8/yolov8s_best.pt"
    device: cpu
  classify_card_side:
    weight: "./ckpt_saved_model/class_yolov8/yolov8n_best.pt"
    device: cpu
  detect_text_yolov8:
    weight: "./ckpt_saved_model/detect_text_yolov8/detect_text_best.pt"
    device: cpu
  recognize_face_text:
    net:
      # change to list chars of your dataset or use default vietnamese chars
      vocab: 'aAàÀảẢãÃáÁạẠăĂằẰẳẲẵẴắẮặẶâÂầẦẩẨẫẪấẤậẬbBcCdDđĐeEèÈẻẺẽẼéÉẹẸêÊềỀểỂễỄếẾệỆfFgGhHiIìÌỉỈĩĨíÍịỊjJkKlLmMnNoOòÒỏỎõÕóÓọỌôÔồỒổỔỗỖốỐộỘơƠờỜởỞỡỠớỚợỢpPqQrRsStTuUùÙủỦũŨúÚụỤưƯừỪửỬữỮứỨựỰvVwWxXyYỳỲỷỶỹỸýÝỵỴzZ0123456789!"#$%&''()*+,-./:;<=>?@[\]^_`{|}~ '

      # cpu, cuda, cuda:0
      device: cpu

      seq_modeling: transformer
      transformer:
        d_model: 256
        nhead: 8
        num_encoder_layers: 6
        num_decoder_layers: 6
        dim_feedforward: 2048
        max_seq_length: 1024
        pos_dropout: 0.1
        trans_dropout: 0.1

      optimizer:
        max_lr: 0.0003
        pct_start: 0.1

      trainer:
        batch_size: 32
        print_every: 200
        valid_every: 4000
        iters: 100000
        # where to save our model for prediction
        export: ./weights/transformerocr.pth
        checkpoint: ./checkpoint/transformerocr_checkpoint.pth
        log: ./train.log
        # null to disable compuate accuracy, or change to number of sample to enable validiation while training
        metrics: null

      dataset:
        # name of your dataset
        name: data
        # path to annotation and image
        data_root: ./img/
        train_annotation: annotation_train.txt
        valid_annotation: annotation_val_small.txt
        # resize image to 32 height, larger height will increase accuracy
        image_height: 32
        image_min_width: 32
        image_max_width: 512

      dataloader:
        num_workers: 3
        pin_memory: True

      aug:
        image_aug: true
        masked_language_model: true

      predictor:
        # disable or enable beamsearch while prediction, use beamsearch will be slower
        beamsearch: False

      quiet: False
  transformer:
    pretrain:
      id_or_url: 13327Y1tz1ohsm5YZMyXVMPIOjoOA0OaA
      md5: af6b46e9295eb1c27ca90bddf8c8729a
      cached: /tmp/tranformerorc.pth

    # url or local path
    weights: ./ckpt_saved_model/recognition/saved_model/transformerocr/transformerocr_new.pth

    backbone: vgg19_bn
    cnn:
      pretrained: False
      # pooling stride size
      ss:
        - [ 2, 2 ]
        - [ 2, 2 ]
        - [ 2, 1 ]
        - [ 2, 1 ]
        - [ 1, 1 ]
      # pooling kernel size
      ks:
        - [ 2, 2 ]
        - [ 2, 2 ]
        - [ 2, 1 ]
        - [ 2, 1 ]
        - [ 1, 1 ]
      # dim of ouput feature map
      hidden: 256
  seq2seg:
    pretrain:
      id_or_url: 1nTKlEog9YFK74kPyX0qLwCWi60_YHHk4
      md5: efcabaa6d3adfca8e52bda2fd7d2ee04
      cached: /tmp/tranformerorc.pth

    # url or local path
    weights: ./ckpt_saved_model/recognition/saved_model/transformerocr/new.pth

    backbone: vgg19_bn
    cnn:
      # pooling stride size
      pretrained: False
      ss:
        - [ 2, 2 ]
        - [ 2, 2 ]
        - [ 2, 1 ]
        - [ 2, 1 ]
        - [ 1, 1 ]
      # pooling kernel size
      ks:
        - [ 2, 2 ]
        - [ 2, 2 ]
        - [ 2, 1 ]
        - [ 2, 1 ]
        - [ 1, 1 ]
      # dim of ouput feature map
      hidden: 256

    seq_modeling: seq2seq
    transformer:
      encoder_hidden: 256
      decoder_hidden: 256
      img_channel: 256
      decoder_embedded: 256
      dropout: 0.1

    optimizer:
      max_lr: 0.001
      pct_start: 0.1